{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Prepare Data</h1>\n",
    "<p>Best Models So Far: Random Forest and RBF SVMs</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "SECONDS_IN_YEAR = (dt.datetime(2021, 1, 1) - dt.datetime(2020, 1, 1)).total_seconds()\n",
    "\n",
    "def get_population_density(location):\n",
    "    if location == \"Kenosha;WI\":\n",
    "        return 1\n",
    "    elif location == \"Hackensack;NJ\":\n",
    "        return 2\n",
    "\n",
    "def get_SINE(date):\n",
    "    seconds = (date - dt.datetime(2020, 1, 1, 0)).total_seconds()\n",
    "    return np.sin(2 * np.pi * seconds / SECONDS_IN_YEAR)\n",
    "\n",
    "def get_COSINE(date):\n",
    "    seconds = (date - dt.datetime(2020, 1, 1, 0)).total_seconds()\n",
    "    return np.cos(2 * np.pi * seconds / SECONDS_IN_YEAR)\n",
    "\n",
    "def get_hour_difference(start_datetime, end_datetime):\n",
    "    return (end_datetime - start_datetime).total_seconds() / 3600\n",
    "\n",
    "# Import file 1\n",
    "import_file = \"DoorDash_Kenosha_WI_V1.csv\"\n",
    "columns = [\"Location\", \"Start_Datetime\", \"End_Datetime\", \"Base\", \"Peak\", \"Tip\", \"Total\"]\n",
    "df1 = pd.read_csv(import_file, names=columns)\n",
    "\n",
    "# Import file 2\n",
    "import_file = \"DoorDash_Kenosha_WI_V2.csv\"\n",
    "columns = [\"Location\", \"Start_Datetime\", \"End_Datetime\", \"DPH\", \"TEPH\"]\n",
    "df2 = pd.read_csv(import_file, names=columns)\n",
    "\n",
    "# Change to numerical data for df1\n",
    "df1[\"Location\"] = df1[\"Location\"].map(get_population_density)\n",
    "df1[\"Start_Datetime\"] = pd.to_datetime(df1[\"Start_Datetime\"], format=\"%Y-%m-%dT%H:%MZ\", errors=\"coerce\")\n",
    "df1[\"DayOfWeek\"] = df1[\"Start_Datetime\"].dt.dayofweek\n",
    "df1[\"Start_Datetime\"] = (df1[\"Start_Datetime\"] - dt.datetime(2020, 1, 1)).dt.total_seconds()\n",
    "df1[\"Start_Datetime_SINE\"] = np.sin(2 * np.pi * df1[\"Start_Datetime\"] / SECONDS_IN_YEAR)\n",
    "df1[\"Start_Datetime_COSINE\"] = np.cos(2 * np.pi * df1[\"Start_Datetime\"] / SECONDS_IN_YEAR)\n",
    "df1[\"End_Datetime\"] = pd.to_datetime(df1[\"End_Datetime\"], format=\"%Y-%m-%dT%H:%MZ\", errors=\"coerce\")\n",
    "df1[\"End_Datetime\"] = (df1[\"End_Datetime\"] - dt.datetime(2020, 1, 1)).dt.total_seconds()\n",
    "df1[\"End_Datetime_SINE\"] = np.sin(2 * np.pi * df1[\"End_Datetime\"] / SECONDS_IN_YEAR)\n",
    "df1[\"End_Datetime_COSINE\"] = np.cos(2 * np.pi * df1[\"End_Datetime\"] / SECONDS_IN_YEAR)\n",
    "df1 = df1[[\"Location\", \"Start_Datetime_SINE\", \"Start_Datetime_COSINE\", \"End_Datetime_SINE\", \"End_Datetime_COSINE\", \"DayOfWeek\", \"Base\", \"Peak\", \"Tip\", \"Total\"]]\n",
    "\n",
    "# Change to numerical data for df2\n",
    "df2[\"Location\"] = df2[\"Location\"].map(get_population_density)\n",
    "df2[\"Start_Datetime\"] = pd.to_datetime(df2[\"Start_Datetime\"], format=\"%Y-%m-%dT%H:%MZ\", errors=\"coerce\")\n",
    "df2[\"DayOfWeek\"] = df2[\"Start_Datetime\"].dt.dayofweek\n",
    "df2[\"Start_Datetime\"] = (df2[\"Start_Datetime\"] - dt.datetime(2020, 1, 1)).dt.total_seconds()\n",
    "df2[\"Start_Datetime_SINE\"] = np.sin(2 * np.pi * df2[\"Start_Datetime\"] / SECONDS_IN_YEAR)\n",
    "df2[\"Start_Datetime_COSINE\"] = np.cos(2 * np.pi * df2[\"Start_Datetime\"] / SECONDS_IN_YEAR)\n",
    "df2[\"End_Datetime\"] = pd.to_datetime(df2[\"End_Datetime\"], format=\"%Y-%m-%dT%H:%MZ\", errors=\"coerce\")\n",
    "df2[\"End_Datetime\"] = (df2[\"End_Datetime\"] - dt.datetime(2020, 1, 1)).dt.total_seconds()\n",
    "df2[\"End_Datetime_SINE\"] = np.sin(2 * np.pi * df2[\"End_Datetime\"] / SECONDS_IN_YEAR)\n",
    "df2[\"End_Datetime_COSINE\"] = np.cos(2 * np.pi * df2[\"End_Datetime\"] / SECONDS_IN_YEAR)\n",
    "df2 = df2[[\"Location\", \"Start_Datetime_SINE\", \"Start_Datetime_COSINE\", \"End_Datetime_SINE\", \"End_Datetime_COSINE\", \"DayOfWeek\", \"DPH\", \"TEPH\"]]\n",
    "\n",
    "# Separate features and classes for df1\n",
    "feature_names = [\"Location\", \"Start_Datetime_SINE\", \"Start_Datetime_COSINE\", \"End_Datetime_SINE\", \"End_Datetime_COSINE\", \"DayOfWeek\"]\n",
    "all_features_df1 = df1[feature_names].values\n",
    "all_classes_base = df1[\"Base\"].values\n",
    "all_classes_peak = df1[\"Peak\"].values\n",
    "all_classes_tip = df1[\"Tip\"].values\n",
    "all_classes_total = df1[\"Total\"].values\n",
    "\n",
    "# Separate features and classes for df2\n",
    "feature_names = [\"Location\", \"Start_Datetime_SINE\", \"Start_Datetime_COSINE\", \"End_Datetime_SINE\", \"End_Datetime_COSINE\", \"DayOfWeek\"]\n",
    "all_features_df2 = df2[feature_names].values\n",
    "all_classes_DPH = df2[\"DPH\"].values\n",
    "all_classes_TEPH = df2[\"TEPH\"].values\n",
    "\n",
    "# Normalize data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "all_features_df1_scaled = scaler.fit_transform(all_features_df1)\n",
    "all_features_df2_scaled = scaler.fit_transform(all_features_df2)\n",
    "\n",
    "# Test inputs\n",
    "location = get_population_density(\"Hackensack;NJ\")\n",
    "start_datetime = dt.datetime(2020, 10, 5, 6, 0)\n",
    "end_datetime = dt.datetime(2020, 10, 5, 7, 0)\n",
    "start_datetime_SINE = get_SINE(start_datetime)\n",
    "start_datetime_COSINE = get_COSINE(start_datetime)\n",
    "end_datetime_SINE = get_SINE(end_datetime)\n",
    "end_datetime_COSINE = get_COSINE(end_datetime)\n",
    "dayOfWeek = start_datetime.weekday()\n",
    "hour_difference = get_hour_difference(start_datetime, end_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Start_Datetime_SINE</th>\n",
       "      <th>Start_Datetime_COSINE</th>\n",
       "      <th>End_Datetime_SINE</th>\n",
       "      <th>End_Datetime_COSINE</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Base</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Tip</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1247.0</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.595500</td>\n",
       "      <td>-0.371143</td>\n",
       "      <td>0.594476</td>\n",
       "      <td>-0.373265</td>\n",
       "      <td>2.757017</td>\n",
       "      <td>2.935044</td>\n",
       "      <td>0.632719</td>\n",
       "      <td>5.254980</td>\n",
       "      <td>8.824346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567789</td>\n",
       "      <td>0.430878</td>\n",
       "      <td>0.568531</td>\n",
       "      <td>0.429478</td>\n",
       "      <td>1.912906</td>\n",
       "      <td>0.645153</td>\n",
       "      <td>1.126004</td>\n",
       "      <td>2.364477</td>\n",
       "      <td>2.643884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.863331</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.864633</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.225114</td>\n",
       "      <td>-0.711678</td>\n",
       "      <td>0.223824</td>\n",
       "      <td>-0.714353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902169</td>\n",
       "      <td>-0.431382</td>\n",
       "      <td>0.900750</td>\n",
       "      <td>-0.434338</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979002</td>\n",
       "      <td>0.017846</td>\n",
       "      <td>0.978252</td>\n",
       "      <td>0.014735</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.398202</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.395138</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>19.420000</td>\n",
       "      <td>23.920000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Location  Start_Datetime_SINE  Start_Datetime_COSINE  \\\n",
       "count    1247.0          1247.000000            1247.000000   \n",
       "mean        1.0             0.595500              -0.371143   \n",
       "std         0.0             0.567789               0.430878   \n",
       "min         1.0            -0.863331              -0.999999   \n",
       "25%         1.0             0.225114              -0.711678   \n",
       "50%         1.0             0.902169              -0.431382   \n",
       "75%         1.0             0.979002               0.017846   \n",
       "max         1.0             1.000000               0.398202   \n",
       "\n",
       "       End_Datetime_SINE  End_Datetime_COSINE    DayOfWeek         Base  \\\n",
       "count        1247.000000          1247.000000  1247.000000  1247.000000   \n",
       "mean            0.594476            -0.373265     2.757017     2.935044   \n",
       "std             0.568531             0.429478     1.912906     0.645153   \n",
       "min            -0.864633            -0.999999     0.000000     2.000000   \n",
       "25%             0.223824            -0.714353     1.000000     3.000000   \n",
       "50%             0.900750            -0.434338     3.000000     3.000000   \n",
       "75%             0.978252             0.014735     4.000000     3.000000   \n",
       "max             0.999980             0.395138     6.000000     7.500000   \n",
       "\n",
       "              Peak          Tip        Total  \n",
       "count  1247.000000  1247.000000  1247.000000  \n",
       "mean      0.632719     5.254980     8.824346  \n",
       "std       1.126004     2.364477     2.643884  \n",
       "min       0.000000     0.000000     2.000000  \n",
       "25%       0.000000     4.000000     7.000000  \n",
       "50%       0.000000     5.000000     8.000000  \n",
       "75%       1.000000     6.000000    10.000000  \n",
       "max       6.000000    19.420000    23.920000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Start_Datetime_SINE</th>\n",
       "      <th>Start_Datetime_COSINE</th>\n",
       "      <th>End_Datetime_SINE</th>\n",
       "      <th>End_Datetime_COSINE</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DPH</th>\n",
       "      <th>TEPH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>158.0</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.517903</td>\n",
       "      <td>-0.419314</td>\n",
       "      <td>0.516944</td>\n",
       "      <td>-0.420813</td>\n",
       "      <td>2.569620</td>\n",
       "      <td>2.142722</td>\n",
       "      <td>18.825823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606759</td>\n",
       "      <td>0.437420</td>\n",
       "      <td>0.607448</td>\n",
       "      <td>0.436156</td>\n",
       "      <td>1.879718</td>\n",
       "      <td>0.519547</td>\n",
       "      <td>4.876560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.863331</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.864633</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>-0.747335</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>-0.748760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>16.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855939</td>\n",
       "      <td>-0.506966</td>\n",
       "      <td>0.854199</td>\n",
       "      <td>-0.507836</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>18.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.967761</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>0.968308</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.407500</td>\n",
       "      <td>22.197500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.398202</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.395138</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>34.030000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Location  Start_Datetime_SINE  Start_Datetime_COSINE  \\\n",
       "count     158.0           158.000000             158.000000   \n",
       "mean        1.0             0.517903              -0.419314   \n",
       "std         0.0             0.606759               0.437420   \n",
       "min         1.0            -0.863331              -0.999999   \n",
       "25%         1.0             0.005478              -0.747335   \n",
       "50%         1.0             0.855939              -0.506966   \n",
       "75%         1.0             0.967761               0.010106   \n",
       "max         1.0             1.000000               0.398202   \n",
       "\n",
       "       End_Datetime_SINE  End_Datetime_COSINE   DayOfWeek         DPH  \\\n",
       "count         158.000000           158.000000  158.000000  158.000000   \n",
       "mean            0.516944            -0.420813    2.569620    2.142722   \n",
       "std             0.607448             0.436156    1.879718    0.519547   \n",
       "min            -0.864633            -0.999999    0.000000    0.250000   \n",
       "25%             0.002140            -0.748760    1.000000    1.880000   \n",
       "50%             0.854199            -0.507836    2.000000    2.130000   \n",
       "75%             0.968308             0.006777    4.000000    2.407500   \n",
       "max             0.999980             0.395138    6.000000    4.030000   \n",
       "\n",
       "             TEPH  \n",
       "count  158.000000  \n",
       "mean    18.825823  \n",
       "std      4.876560  \n",
       "min      1.720000  \n",
       "25%     16.235000  \n",
       "50%     18.545000  \n",
       "75%     22.197500  \n",
       "max     34.030000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Calculation: 18.90811698963588\n",
      "Total STD Calculation: 3.870127599112604\n",
      "TEPH Calculation: 18.825822784810125\n",
      "TEPH STD Calculation: 4.8765598471583465\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "total_mean = df1[\"Total\"].mean()\n",
    "DPH_mean = df2[\"DPH\"].mean()\n",
    "print(\"Total Calculation:\", total_mean * DPH_mean * hour_difference)\n",
    "total_std = df1[\"Total\"].std()\n",
    "total_variance = total_std * total_std\n",
    "total_test_std = math.sqrt(total_variance * DPH_mean * hour_difference)\n",
    "print(\"Total STD Calculation:\", total_test_std)\n",
    "\n",
    "TEPH_mean = df2[\"TEPH\"].mean()\n",
    "print(\"TEPH Calculation:\", TEPH_mean * hour_difference)\n",
    "TEPH_std = df2[\"TEPH\"].std()\n",
    "TEPH_variance = TEPH_std * TEPH_std\n",
    "TEPH_test_std = math.sqrt(TEPH_variance * hour_difference)\n",
    "print(\"TEPH STD Calculation:\", TEPH_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.9089015151515154, -0.20160678717620445, 'Base'], [1.2708333333333335, -1.1908936444530118, 'Peak'], [5.394583333333334, -0.11065689775955123, 'Tip'], [9.327636904761905, -0.12892944110926788, 'Total'], [1.85, -0.5382985294080384, 'DPH'], [18.078, -0.3354776571122365, 'TEPH']]\n",
      "Total Calculation: 17.256128273809523\n",
      "Total STD Calculation: 3.5960712062821756\n",
      "TEPH Calculation: 18.078\n",
      "TEPH STD Calculation: 4.8765598471583465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=10, random_state=1)\n",
    "\n",
    "# Return random forest estimates and k-fold cross-validation scores\n",
    "def get_random_forest(location, start_datetime_SINE, start_datetime_COSINE, end_datetime_SINE, end_datetime_COSINE, dayOfWeek):\n",
    "    test_input = [[location, start_datetime_SINE, start_datetime_COSINE, end_datetime_SINE, end_datetime_COSINE, dayOfWeek]]\n",
    "    # Base\n",
    "    cv_scores = cross_val_score(clf, all_features_df1_scaled, all_classes_base, cv=10)\n",
    "    base_k = cv_scores.mean()\n",
    "    clf.fit(all_features_df1_scaled, all_classes_base)\n",
    "    base = clf.predict(test_input)[0]\n",
    "    base_array = [base, base_k, \"Base\"]\n",
    "    # Peak\n",
    "    cv_scores = cross_val_score(clf, all_features_df1_scaled, all_classes_peak, cv=10)\n",
    "    peak_k = cv_scores.mean()\n",
    "    clf.fit(all_features_df1_scaled, all_classes_peak)\n",
    "    peak = clf.predict(test_input)[0]\n",
    "    peak_array = [peak, peak_k, \"Peak\"]\n",
    "    # Tip\n",
    "    cv_scores = cross_val_score(clf, all_features_df1_scaled, all_classes_tip, cv=10)\n",
    "    tip_k = cv_scores.mean()\n",
    "    clf.fit(all_features_df1_scaled, all_classes_tip)\n",
    "    tip = clf.predict(test_input)[0]\n",
    "    tip_array = [tip, tip_k, \"Tip\"]\n",
    "    # Total\n",
    "    cv_scores = cross_val_score(clf, all_features_df1_scaled, all_classes_total, cv=10)\n",
    "    total_k = cv_scores.mean()\n",
    "    clf.fit(all_features_df1_scaled, all_classes_total)\n",
    "    total = clf.predict(test_input)[0]\n",
    "    total_array = [total, total_k, \"Total\"]\n",
    "    # DPH\n",
    "    cv_scores = cross_val_score(clf, all_features_df2_scaled, all_classes_DPH, cv=10)\n",
    "    DPH_k = cv_scores.mean()\n",
    "    clf.fit(all_features_df2_scaled, all_classes_DPH)\n",
    "    DPH = clf.predict(test_input)[0]\n",
    "    DPH_array = [DPH, DPH_k, \"DPH\"]\n",
    "    # TEPH\n",
    "    cv_scores = cross_val_score(clf, all_features_df2_scaled, all_classes_TEPH, cv=10)\n",
    "    TEPH_k = cv_scores.mean()\n",
    "    clf.fit(all_features_df2_scaled, all_classes_TEPH)\n",
    "    TEPH = clf.predict(test_input)[0]\n",
    "    TEPH_array = [TEPH, TEPH_k, \"TEPH\"]\n",
    "    return [base_array, peak_array, tip_array, total_array, DPH_array, TEPH_array]\n",
    "\n",
    "estimates = get_random_forest(location, start_datetime_SINE, start_datetime_COSINE, end_datetime_SINE, end_datetime_COSINE, dayOfWeek)\n",
    "print(estimates)\n",
    "\n",
    "print(\"Total Calculation:\", estimates[3][0] * estimates[4][0] * hour_difference)\n",
    "total_test_std = math.sqrt(total_variance * estimates[4][0] * hour_difference)\n",
    "print(\"Total STD Calculation:\", total_test_std)\n",
    "\n",
    "print(\"TEPH Calculation:\", estimates[5][0] * hour_difference)\n",
    "TEPH_test_std = math.sqrt(TEPH_variance * hour_difference)\n",
    "print(\"TEPH STD Calculation:\", TEPH_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Linear SVM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.899965298556714, -0.021787612713334892, 'Base'], [0.1002438860846637, -0.2888180979355207, 'Peak'], [4.985695745189954, -0.03528083618764792, 'Tip'], [8.370295628976567, -0.01799587504508974, 'Total'], [1.94601293391354, -0.13340048295964888, 'DPH'], [17.26888391905293, -0.3487516384095234, 'TEPH']]\n",
      "Total Calculation: 16.28870355466837\n",
      "Total STD Calculation: 3.6882069312762864\n",
      "TEPH Calculation: 17.26888391905293\n",
      "TEPH STD Calculation: 4.8765598471583465\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Hyperparameters\n",
    "C = 1.0\n",
    "\n",
    "svr = svm.SVR(kernel=\"linear\", C=C)\n",
    "\n",
    "# Return linear SVM estimates and k-fold cross-validation scores\n",
    "def get_linear_SVM(location, start_datetime_SINE, start_datetime_COSINE, end_datetime_SINE, end_datetime_COSINE, dayOfWeek):\n",
    "    test_input = [[location, start_datetime_SINE, start_datetime_COSINE, end_datetime_SINE, end_datetime_COSINE, dayOfWeek]]\n",
    "    # Base\n",
    "    cv_scores = cross_val_score(svr, all_features_df1_scaled, all_classes_base, cv=10)\n",
    "    base_k = cv_scores.mean()\n",
    "    svr.fit(all_features_df1_scaled, all_classes_base)\n",
    "    base = svr.predict(test_input)[0]\n",
    "    base_array = [base, base_k, \"Base\"]\n",
    "    # Peak\n",
    "    cv_scores = cross_val_score(svr, all_features_df1_scaled, all_classes_peak, cv=10)\n",
    "    peak_k = cv_scores.mean()\n",
    "    svr.fit(all_features_df1_scaled, all_classes_peak)\n",
    "    peak = svr.predict(test_input)[0]\n",
    "    peak_array = [peak, peak_k, \"Peak\"]\n",
    "    # Tip\n",
    "    cv_scores = cross_val_score(svr, all_features_df1_scaled, all_classes_tip, cv=10)\n",
    "    tip_k = cv_scores.mean()\n",
    "    svr.fit(all_features_df1_scaled, all_classes_tip)\n",
    "    tip = svr.predict(test_input)[0]\n",
    "    tip_array = [tip, tip_k, \"Tip\"]\n",
    "    # Total\n",
    "    cv_scores = cross_val_score(svr, all_features_df1_scaled, all_classes_total, cv=10)\n",
    "    total_k = cv_scores.mean()\n",
    "    svr.fit(all_features_df1_scaled, all_classes_total)\n",
    "    total = svr.predict(test_input)[0]\n",
    "    total_array = [total, total_k, \"Total\"]\n",
    "    # DPH\n",
    "    cv_scores = cross_val_score(svr, all_features_df2_scaled, all_classes_DPH, cv=10)\n",
    "    DPH_k = cv_scores.mean()\n",
    "    svr.fit(all_features_df2_scaled, all_classes_DPH)\n",
    "    DPH = svr.predict(test_input)[0]\n",
    "    DPH_array = [DPH, DPH_k, \"DPH\"]\n",
    "    # TEPH\n",
    "    cv_scores = cross_val_score(svr, all_features_df2_scaled, all_classes_TEPH, cv=10)\n",
    "    TEPH_k = cv_scores.mean()\n",
    "    svr.fit(all_features_df2_scaled, all_classes_TEPH)\n",
    "    TEPH = svr.predict(test_input)[0]\n",
    "    TEPH_array = [TEPH, TEPH_k, \"TEPH\"]\n",
    "    return [base_array, peak_array, tip_array, total_array, DPH_array, TEPH_array]\n",
    "\n",
    "estimates = get_linear_SVM(location, start_datetime_SINE, start_datetime_COSINE, end_datetime_SINE, end_datetime_COSINE, dayOfWeek)\n",
    "print(estimates)\n",
    "\n",
    "print(\"Total Calculation:\", estimates[3][0] * estimates[4][0] * hour_difference)\n",
    "total_test_std = math.sqrt(total_variance * estimates[4][0] * hour_difference)\n",
    "print(\"Total STD Calculation:\", total_test_std)\n",
    "\n",
    "print(\"TEPH Calculation:\", estimates[5][0] * hour_difference)\n",
    "TEPH_test_std = math.sqrt(TEPH_variance * hour_difference)\n",
    "print(\"TEPH STD Calculation:\", TEPH_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>RBF SVM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.945620709335246, -0.0237374286088629, 'Base'], [0.29223805451695856, -0.6215163903294936, 'Peak'], [4.8802761710025, -0.049936759962413, 'Tip'], [8.399370819969398, -0.05483948596850261, 'Total'], [2.0705172115599937, -0.1432492581290766, 'DPH'], [18.4974107455068, -0.29583132639943555, 'TEPH']]\n",
      "Total Calculation: 17.391041849021416\n",
      "Total STD Calculation: 3.8043620517892283\n",
      "TEPH Calculation: 18.4974107455068\n",
      "TEPH STD Calculation: 4.8765598471583465\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Hyperparameters\n",
    "C = 1.0\n",
    "\n",
    "svr = svm.SVR(kernel=\"rbf\", C=C)\n",
    "\n",
    "# Return RBF SVM estimates and k-fold cross-validation scores\n",
    "def get_RBF_SVM(location, start_datetime_SINE, start_datetime_COSINE, end_datetime_SINE, end_datetime_COSINE, dayOfWeek):\n",
    "    test_input = [[location, start_datetime_SINE, start_datetime_COSINE, end_datetime_SINE, end_datetime_COSINE, dayOfWeek]]\n",
    "    # Base\n",
    "    cv_scores = cross_val_score(svr, all_features_df1_scaled, all_classes_base, cv=10)\n",
    "    base_k = cv_scores.mean()\n",
    "    svr.fit(all_features_df1_scaled, all_classes_base)\n",
    "    base = svr.predict(test_input)[0]\n",
    "    base_array = [base, base_k, \"Base\"]\n",
    "    # Peak\n",
    "    cv_scores = cross_val_score(svr, all_features_df1_scaled, all_classes_peak, cv=10)\n",
    "    peak_k = cv_scores.mean()\n",
    "    svr.fit(all_features_df1_scaled, all_classes_peak)\n",
    "    peak = svr.predict(test_input)[0]\n",
    "    peak_array = [peak, peak_k, \"Peak\"]\n",
    "    # Tip\n",
    "    cv_scores = cross_val_score(svr, all_features_df1_scaled, all_classes_tip, cv=10)\n",
    "    tip_k = cv_scores.mean()\n",
    "    svr.fit(all_features_df1_scaled, all_classes_tip)\n",
    "    tip = svr.predict(test_input)[0]\n",
    "    tip_array = [tip, tip_k, \"Tip\"]\n",
    "    # Total\n",
    "    cv_scores = cross_val_score(svr, all_features_df1_scaled, all_classes_total, cv=10)\n",
    "    total_k = cv_scores.mean()\n",
    "    svr.fit(all_features_df1_scaled, all_classes_total)\n",
    "    total = svr.predict(test_input)[0]\n",
    "    total_array = [total, total_k, \"Total\"]\n",
    "    # DPH\n",
    "    cv_scores = cross_val_score(svr, all_features_df2_scaled, all_classes_DPH, cv=10)\n",
    "    DPH_k = cv_scores.mean()\n",
    "    svr.fit(all_features_df2_scaled, all_classes_DPH)\n",
    "    DPH = svr.predict(test_input)[0]\n",
    "    DPH_array = [DPH, DPH_k, \"DPH\"]\n",
    "    # TEPH\n",
    "    cv_scores = cross_val_score(svr, all_features_df2_scaled, all_classes_TEPH, cv=10)\n",
    "    TEPH_k = cv_scores.mean()\n",
    "    svr.fit(all_features_df2_scaled, all_classes_TEPH)\n",
    "    TEPH = svr.predict(test_input)[0]\n",
    "    TEPH_array = [TEPH, TEPH_k, \"TEPH\"]\n",
    "    return [base_array, peak_array, tip_array, total_array, DPH_array, TEPH_array]\n",
    "\n",
    "estimates = get_RBF_SVM(location, start_datetime_SINE, start_datetime_COSINE, end_datetime_SINE, end_datetime_COSINE, dayOfWeek)\n",
    "print(estimates)\n",
    "\n",
    "print(\"Total Calculation:\", estimates[3][0] * estimates[4][0] * hour_difference)\n",
    "total_test_std = math.sqrt(total_variance * estimates[4][0] * hour_difference)\n",
    "print(\"Total STD Calculation:\", total_test_std)\n",
    "\n",
    "print(\"TEPH Calculation:\", estimates[5][0] * hour_difference)\n",
    "TEPH_test_std = math.sqrt(TEPH_variance * hour_difference)\n",
    "print(\"TEPH STD Calculation:\", TEPH_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K-Nearest Neighbors</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.9, -0.1346326353550232, 'Base'], [0.3, -0.7809615373769722, 'Peak'], [6.294, -0.14381924065801707, 'Tip'], [9.494, -0.15185535441263334, 'Total'], [1.908, -0.1861387035216599, 'DPH'], [17.006999999999998, -0.27448851878140806, 'TEPH']]\n",
      "Total Calculation: 18.114552\n",
      "Total STD Calculation: 3.6520070197827446\n",
      "TEPH Calculation: 17.006999999999998\n",
      "TEPH STD Calculation: 4.8765598471583465\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "# Find optimal value for neighbors\n",
    "#for n in range(1, 50):\n",
    "#    clf = neighbors.KNeighborsRegressor(n_neighbors=n)\n",
    "#    cv_scores = cross_val_score(clf, all_features_scaled, all_classes_base, cv=10)\n",
    "#    print(n, cv_scores.mean())\n",
    "\n",
    "# Return KNN estimates and k-fold cross-validation scores\n",
    "def get_KNN(location, start_datetime_SINE, start_datetime_COSINE, end_datetime_SINE, end_datetime_COSINE, dayOfWeek):\n",
    "    test_input = [[location, start_datetime_SINE, start_datetime_COSINE, end_datetime_SINE, end_datetime_COSINE, dayOfWeek]]\n",
    "    # Base\n",
    "    cv_scores = cross_val_score(clf, all_features_df1_scaled, all_classes_base, cv=10)\n",
    "    base_k = cv_scores.mean()\n",
    "    clf.fit(all_features_df1_scaled, all_classes_base)\n",
    "    base = clf.predict(test_input)[0]\n",
    "    base_array = [base, base_k, \"Base\"]\n",
    "    # Peak\n",
    "    cv_scores = cross_val_score(clf, all_features_df1_scaled, all_classes_peak, cv=10)\n",
    "    peak_k = cv_scores.mean()\n",
    "    clf.fit(all_features_df1_scaled, all_classes_peak)\n",
    "    peak = clf.predict(test_input)[0]\n",
    "    peak_array = [peak, peak_k, \"Peak\"]\n",
    "    # Tip\n",
    "    cv_scores = cross_val_score(clf, all_features_df1_scaled, all_classes_tip, cv=10)\n",
    "    tip_k = cv_scores.mean()\n",
    "    clf.fit(all_features_df1_scaled, all_classes_tip)\n",
    "    tip = clf.predict(test_input)[0]\n",
    "    tip_array = [tip, tip_k, \"Tip\"]\n",
    "    # Total\n",
    "    cv_scores = cross_val_score(clf, all_features_df1_scaled, all_classes_total, cv=10)\n",
    "    total_k = cv_scores.mean()\n",
    "    clf.fit(all_features_df1_scaled, all_classes_total)\n",
    "    total = clf.predict(test_input)[0]\n",
    "    total_array = [total, total_k, \"Total\"]\n",
    "    # DPH\n",
    "    cv_scores = cross_val_score(clf, all_features_df2_scaled, all_classes_DPH, cv=10)\n",
    "    DPH_k = cv_scores.mean()\n",
    "    clf.fit(all_features_df2_scaled, all_classes_DPH)\n",
    "    DPH = clf.predict(test_input)[0]\n",
    "    DPH_array = [DPH, DPH_k, \"DPH\"]\n",
    "    # TEPH\n",
    "    cv_scores = cross_val_score(clf, all_features_df2_scaled, all_classes_TEPH, cv=10)\n",
    "    TEPH_k = cv_scores.mean()\n",
    "    clf.fit(all_features_df2_scaled, all_classes_TEPH)\n",
    "    TEPH = clf.predict(test_input)[0]\n",
    "    TEPH_array = [TEPH, TEPH_k, \"TEPH\"]\n",
    "    return [base_array, peak_array, tip_array, total_array, DPH_array, TEPH_array]\n",
    "\n",
    "estimates = get_KNN(location, start_datetime_SINE, start_datetime_COSINE, end_datetime_SINE, end_datetime_COSINE, dayOfWeek)\n",
    "print(estimates)\n",
    "\n",
    "print(\"Total Calculation:\", estimates[3][0] * estimates[4][0] * hour_difference)\n",
    "total_test_std = math.sqrt(total_variance * estimates[4][0] * hour_difference)\n",
    "print(\"Total STD Calculation:\", total_test_std)\n",
    "\n",
    "print(\"TEPH Calculation:\", estimates[5][0] * hour_difference)\n",
    "TEPH_test_std = math.sqrt(TEPH_variance * hour_difference)\n",
    "print(\"TEPH STD Calculation:\", TEPH_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Neural Network</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Base Pay</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Create model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=5, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "    model.add(Dense(3, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "    model.add(Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_features_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-556bead70e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# K-Fold Cross-Validation (Base)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_features_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_classes_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_features_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "estimator = KerasRegressor(build_fn=create_model, epochs=100, verbose=0)\n",
    "\n",
    "# K-Fold Cross-Validation (Base)\n",
    "cv_scores = cross_val_score(estimator, all_features_scaled, all_classes_base, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict (Base)\n",
    "estimator.fit(all_features_scaled, all_classes_base)\n",
    "print(estimator.predict(test_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Peak Pay</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation (Peak)\n",
    "cv_scores = cross_val_score(estimator, all_features_scaled, all_classes_peak, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict (Peak)\n",
    "estimator.fit(all_features_scaled, all_classes_peak)\n",
    "print(estimator.predict(test_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Customer Tip</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation (Tip)\n",
    "cv_scores = cross_val_score(estimator, all_features_scaled, all_classes_tip, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict (Tip)\n",
    "estimator.fit(all_features_scaled, all_classes_tip)\n",
    "print(estimator.predict(test_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Total</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation (Total)\n",
    "cv_scores = cross_val_score(estimator, all_features_scaled, all_classes_total, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict (Total)\n",
    "estimator.fit(all_features_scaled, all_classes_total)\n",
    "print(estimator.predict(test_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
